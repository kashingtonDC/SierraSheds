{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import ee\n",
    "import io\n",
    "import tqdm\n",
    "import json\n",
    "import fiona\n",
    "import datetime\n",
    "import requests\n",
    "import urllib.request\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import rsfuncs as rs\n",
    "import rasterio as rio\n",
    "import geopandas as gp\n",
    "import multiprocessing as mp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from affine import Affine\n",
    "from datetime import timedelta\n",
    "from rasterio import features, mask\n",
    "from climata.usgs import DailyValueIO\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read catchments, reservoirs\n",
    "gdf = gp.read_file(\"../shape/sierra_catchments.shp\")\n",
    "reservoirs_gdf = gp.read_file(\"../shape/reservoirs_grace.shp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gcm_dat(shppath, gcm_dir = \"../data/CA_BCM/GISS_26\", var = \"ppt\"):\n",
    "\n",
    "    '''\n",
    "    Given a path to a shapefile, compute the monthly sums of a variable\n",
    "\n",
    "    Inputs: \n",
    "        shppath (str) - path to shapefile\n",
    "        gcm_dir - data directory storing the files\n",
    "        var - name of variable (file suffix)\n",
    "\n",
    "    Output: (pd.DataFrame) - monthly sum of variable \n",
    "    '''\n",
    "\n",
    "    # Find gcm files\n",
    "    data_dir = gcm_dir\n",
    "    files = [os.path.join(data_dir,x) for x in os.listdir(data_dir) if x.endswith(\".tiff\") if var in x]\n",
    "    files.sort()\n",
    "\n",
    "    # Read CVWS shapefile\n",
    "    with fiona.open(shppath, \"r\") as shapefile:\n",
    "        shp_geom = [feature[\"geometry\"] for feature in shapefile]\n",
    "\n",
    "    # Read the files, mask nans, clip to CVWS, extract dates\n",
    "    imdict = {}\n",
    "    outdates = []\n",
    "\n",
    "    for i in tqdm(files[:]):\n",
    "        date = datetime.datetime.strptime(i[-12:-5],'%Y_%m')+ timedelta(days=-1) # Get the date \n",
    "        datestr = date.strftime('%Y_%m') # Format date\n",
    "        src = rio.open(i) # Read file\n",
    "        src2 = rio.mask.mask(src, shp_geom, crop=True) # Clip to shp \n",
    "        arr = src2[0] # read as array\n",
    "        arr = arr.reshape(arr.shape[1], arr.shape[2]).astype(float) # Reshape bc rasterio has a different dim ordering \n",
    "        arr[arr < 0 ] = np.nan # Mask nodata vals \n",
    "        imdict[datestr] = arr * 0.001 # convert mm to m\n",
    "        outdates.append(date)\n",
    "        \n",
    "    # Stack all dates to 3D array\n",
    "    var_stacked = np.dstack(list(imdict.values()))\n",
    "\n",
    "    # Compute monthly sums\n",
    "    monthsums = []\n",
    "    for i in range(var_stacked.shape[2]):\n",
    "        monthsums.append(np.nansum(var_stacked[:,:,i] *275**2 * 1e-9)) # mult by 275^2 m pixel area, convert m^3 to km^3\n",
    "\n",
    "    outdf = pd.DataFrame(monthsums,outdates)\n",
    "    outdf.columns = [var]\n",
    "    return outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1116 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "************************************************************\n",
      "SHA SACRAMENTO R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1116/1116 [06:11<00:00,  3.00it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, x in enumerate(gdf[8:9].iterrows()):\n",
    "    print(idx)\n",
    "    print(\"****\" * 15)\n",
    "    row  = x[1]\n",
    "    stn_id = row['stid']\n",
    "    print(stn_id, row['catch_name'])\n",
    "    \n",
    "    # Read the catchment shapefile\n",
    "    catch_shp = \"../shape/catchment_{}.shp\".format(stn_id)\n",
    "    gcm_dir = \"../data/CA_BCM/GISS_26\"\n",
    "    \n",
    "    # Get the GCM data \n",
    "    ppt_df = get_gcm_dat(catch_shp, gcm_dir = \"../data/CA_BCM/GISS_26\", var = \"ppt\")\n",
    "    aet_df = get_gcm_dat(catch_shp, gcm_dir = \"../data/CA_BCM/GISS_26\", var = \"aet\")\n",
    "    pet_df = get_gcm_dat(catch_shp, gcm_dir = \"../data/CA_BCM/GISS_26\", var = \"pet\")\n",
    "    \n",
    "    # Concat the dfs\n",
    "    mdf = pd.concat([ppt_df, aet_df, pet_df],axis = 1)\n",
    "    \n",
    "    # Write\n",
    "    gcm = os.path.split(gcm_dir)[-1]\n",
    "    write_dir = os.path.join(\"../data/GCM_catchdat/\", gcm)\n",
    "    if not os.path.exists(write_dir):\n",
    "        os.mkdir(write_dir)\n",
    "\n",
    "    outfn = os.path.join(write_dir,\"catch_{}.csv\".format(stn_id))\n",
    "    mdf.to_csv(outfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
